#!/usr/bin/env python3
"""
å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿæµ‹è¯•å’Œæ¼”ç¤ºè„šæœ¬

ç”¨äºæµ‹è¯•æ–°çš„å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿå¹¶ä¸ä¼ ç»ŸRIFè¯„åˆ†è¿›è¡Œå¯¹æ¯”ã€‚
"""

import asyncio
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any

# æ¨¡æ‹Ÿå¯¼å…¥ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦ç¡®ä¿æ­£ç¡®çš„å¯¼å…¥è·¯å¾„ï¼‰
from iris_memory.models.memory import Memory
from iris_memory.analysis.multidimensional_scorer import MultidimensionalScorer, ScenarioType
from iris_memory.analysis.rif_scorer import RIFScorer
from iris_memory.core.types import MemoryType, QualityLevel, SensitivityLevel, StorageLayer


def create_test_memories() -> List[Memory]:
    """åˆ›å»ºæµ‹è¯•è®°å¿†æ•°æ®"""
    now = datetime.now()
    
    memories = [
        # 1. é«˜é¢‘è®¿é—®çš„ä¸ªäººåå¥½
        Memory(
            content="ç”¨æˆ·å–œæ¬¢å–å’–å•¡ï¼Œç‰¹åˆ«æ˜¯æ‹¿é“ï¼Œæ¯å¤©æ—©ä¸Šéƒ½è¦å–ä¸€æ¯",
            type=MemoryType.FACT,
            quality_level=QualityLevel.HIGH_CONFIDENCE,
            confidence=0.85,
            access_count=15,
            last_access_time=now - timedelta(hours=2),
            created_time=now - timedelta(days=30),
            emotional_weight=0.3,
            importance_score=0.7,
            is_user_requested=True,
            consistency_score=0.9,
            keywords=["å’–å•¡", "æ‹¿é“", "æ—©ä¸Š", "åå¥½"]
        ),
        
        # 2. é‡è¦çš„æƒ…æ„Ÿè®°å¿†
        Memory(
            content="ç”¨æˆ·æåˆ°æ˜¨å¤©å’Œå¥³æœ‹å‹åˆ†æ‰‹äº†ï¼Œæ„Ÿåˆ°å¾ˆéš¾è¿‡å’Œå¤±è½",
            type=MemoryType.EMOTION,
            quality_level=QualityLevel.CONFIRMED,
            confidence=0.95,
            access_count=3,
            last_access_time=now - timedelta(hours=1),
            created_time=now - timedelta(hours=26),
            emotional_weight=0.9,
            importance_score=0.8,
            is_user_requested=False,
            consistency_score=1.0,
            sensitivity_level=SensitivityLevel.PRIVATE,
            keywords=["åˆ†æ‰‹", "å¥³æœ‹å‹", "éš¾è¿‡", "å¤±è½"]
        ),
        
        # 3. å…³ç³»è®°å¿†
        Memory(
            content="ç”¨æˆ·çš„å¦¹å¦¹åœ¨ä¸Šæµ·å·¥ä½œï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ",
            type=MemoryType.RELATIONSHIP,
            quality_level=QualityLevel.MODERATE,
            confidence=0.7,
            access_count=2,
            last_access_time=now - timedelta(days=7),
            created_time=now - timedelta(days=60),
            emotional_weight=0.4,
            importance_score=0.6,
            is_user_requested=False,
            consistency_score=0.8,
            sensitivity_level=SensitivityLevel.PERSONAL,
            keywords=["å¦¹å¦¹", "ä¸Šæµ·", "è½¯ä»¶å·¥ç¨‹å¸ˆ", "å®¶äºº"]
        ),
        
        # 4. æ—¥å¸¸äº’åŠ¨è®°å¿†
        Memory(
            content="ç”¨æˆ·è¯¢é—®ä»Šå¤©å¤©æ°”å¦‚ä½•",
            type=MemoryType.INTERACTION,
            quality_level=QualityLevel.LOW_CONFIDENCE,
            confidence=0.4,
            access_count=1,
            last_access_time=now - timedelta(hours=5),
            created_time=now - timedelta(hours=5),
            emotional_weight=0.1,
            importance_score=0.2,
            is_user_requested=False,
            consistency_score=0.5,
            keywords=["å¤©æ°”", "è¯¢é—®"]
        ),
        
        # 5. é™ˆæ—§ä½†é‡è¦çš„è®°å¿†
        Memory(
            content="ç”¨æˆ·çš„ç”Ÿæ—¥æ˜¯3æœˆ15æ—¥ï¼Œä»Šå¹´28å²",
            type=MemoryType.FACT,
            quality_level=QualityLevel.CONFIRMED,
            confidence=1.0,
            access_count=8,
            last_access_time=now - timedelta(days=20),
            created_time=now - timedelta(days=200),
            emotional_weight=0.5,
            importance_score=0.9,
            is_user_requested=True,
            consistency_score=1.0,
            sensitivity_level=SensitivityLevel.PERSONAL,
            keywords=["ç”Ÿæ—¥", "3æœˆ15æ—¥", "28å²", "ä¸ªäººä¿¡æ¯"]
        )
    ]
    
    return memories


def create_test_contexts() -> List[Dict[str, Any]]:
    """åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡"""
    return [
        # æƒ…æ„Ÿå¯¹è¯åœºæ™¯
        {
            "scenario_type": ScenarioType.EMOTIONAL_DIALOGUE,
            "emotional_state": {"type": "sadness", "intensity": 0.8},
            "current_message": "æˆ‘è¿˜æ˜¯å¾ˆæƒ³å¿µå¥¹",
            "query_type": "emotional_support"
        },
        
        # äº‹å®æŸ¥è¯¢åœºæ™¯
        {
            "scenario_type": ScenarioType.FACTUAL_QUERY,
            "emotional_state": {"type": "neutral", "intensity": 0.1},
            "current_message": "æˆ‘çš„ç”Ÿæ—¥æ˜¯ä»€ä¹ˆæ—¶å€™æ¥ç€",
            "query_type": "fact_lookup"
        },
        
        # ç¤¾äº¤åœºæ™¯
        {
            "scenario_type": ScenarioType.SOCIAL_INTERACTION,
            "emotional_state": {"type": "neutral", "intensity": 0.3},
            "current_message": "æˆ‘å¦¹å¦¹æœ€è¿‘æ€ä¹ˆæ ·",
            "query_type": "social_inquiry",
            "group_id": "family_group"
        },
        
        # æ—¥å¸¸é—²èŠ
        {
            "scenario_type": ScenarioType.ROUTINE_CHAT,
            "emotional_state": {"type": "calm", "intensity": 0.2},
            "current_message": "ä»Šå¤©å¤©æ°”çœŸä¸é”™",
            "query_type": "casual_chat"
        },
        
        # é»˜è®¤åœºæ™¯
        {
            "emotional_state": {"type": "neutral", "intensity": 0.5},
            "current_message": "ä½ å¥½"
        }
    ]


async def run_comparison_test():
    """è¿è¡Œå¯¹æ¯”æµ‹è¯•"""
    print("ğŸ”¬ å¤šç»´åº¦è¯„åˆ†ç³»ç»Ÿ vs ä¼ ç»ŸRIFè¯„åˆ†å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–è¯„åˆ†å™¨
    traditional_scorer = RIFScorer(use_multidimensional=False)
    multidimensional_scorer = RIFScorer(
        use_multidimensional=True,
        enable_advanced_features=True,
        enable_context_adaptation=True
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    memories = create_test_memories()
    contexts = create_test_contexts()
    
    print(f"ğŸ“Š æµ‹è¯•æ•°æ®: {len(memories)} æ¡è®°å¿†, {len(contexts)} ç§åœºæ™¯")
    print()
    
    # å¯¹æ¯ä¸ªè®°å¿†åœ¨æ¯ç§åœºæ™¯ä¸‹è¿›è¡Œè¯„åˆ†
    results = []
    
    for i, memory in enumerate(memories):
        print(f"ğŸ“ è®°å¿† {i+1}: {memory.content[:50]}...")
        print(f"   ç±»å‹: {memory.type.value}, ç½®ä¿¡åº¦: {memory.confidence:.2f}, è®¿é—®æ¬¡æ•°: {memory.access_count}")
        print()
        
        for j, context in enumerate(contexts):
            scenario = context.get('scenario_type', 'default')
            print(f"  ğŸ¯ åœºæ™¯ {j+1}: {scenario}")
            
            # ä¼ ç»Ÿè¯„åˆ†
            traditional_score = traditional_scorer.calculate_rif(memory.copy() if hasattr(memory, 'copy') else memory)
            
            # å¤šç»´åº¦è¯„åˆ†
            multidimensional_score = multidimensional_scorer.calculate_rif(memory, context)
            
            # è®¡ç®—å·®å¼‚
            difference = multidimensional_score - traditional_score
            
            print(f"     ä¼ ç»ŸRIF: {traditional_score:.3f}")
            print(f"     å¤šç»´åº¦:  {multidimensional_score:.3f} (å·®å¼‚: {difference:+.3f})")
            print()
            
            results.append({
                'memory_index': i,
                'context_index': j,
                'memory_type': memory.type.value,
                'scenario': scenario,
                'traditional_score': traditional_score,
                'multidimensional_score': multidimensional_score,
                'difference': difference,
                'memory_content': memory.content[:100]
            })
    
    # ç»Ÿè®¡åˆ†æ
    print("ğŸ“ˆ ç»Ÿè®¡åˆ†æ")
    print("-" * 40)
    
    differences = [r['difference'] for r in results]
    avg_diff = sum(differences) / len(differences)
    max_diff = max(differences)
    min_diff = min(differences)
    
    print(f"å¹³å‡å·®å¼‚: {avg_diff:+.3f}")
    print(f"æœ€å¤§å·®å¼‚: {max_diff:+.3f}")
    print(f"æœ€å°å·®å¼‚: {min_diff:+.3f}")
    print()
    
    # æŒ‰åœºæ™¯åˆ†æ
    print("ğŸ¯ æŒ‰åœºæ™¯åˆ†æ")
    print("-" * 40)
    
    scenario_stats = {}
    for result in results:
        scenario = result['scenario']
        if scenario not in scenario_stats:
            scenario_stats[scenario] = []
        scenario_stats[scenario].append(result['difference'])
    
    for scenario, diffs in scenario_stats.items():
        avg_diff = sum(diffs) / len(diffs)
        print(f"{scenario}: å¹³å‡å·®å¼‚ {avg_diff:+.3f}")
    
    print()
    
    # è·å–è¯„åˆ†ç»Ÿè®¡
    print("ğŸ“Š è¯„åˆ†å™¨ç»Ÿè®¡")
    print("-" * 40)
    
    trad_stats = traditional_scorer.get_statistics()
    multi_stats = multidimensional_scorer.get_statistics()
    
    print(f"ä¼ ç»ŸRIFè®¡ç®—æ¬¡æ•°: {trad_stats.get('traditional_calculations', 0)}")
    print(f"å¤šç»´åº¦è®¡ç®—æ¬¡æ•°: {multi_stats.get('multidimensional_calculations', 0)}")
    print(f"å›é€€æ¬¡æ•°: {multi_stats.get('fallbacks', 0)}")
    
    return results


def analyze_detailed_scores():
    """åˆ†æè¯¦ç»†çš„å¤šç»´åº¦å¾—åˆ†"""
    print("\nğŸ” å¤šç»´åº¦å¾—åˆ†è¯¦ç»†åˆ†æ")
    print("=" * 60)
    
    # åˆ›å»ºå¤šç»´åº¦è¯„åˆ†å™¨
    scorer = MultidimensionalScorer(
        enable_advanced_features=True,
        enable_context_adaptation=True
    )
    
    memories = create_test_memories()
    contexts = create_test_contexts()
    
    # é€‰æ‹©ä¸€ä¸ªæœ‰ä»£è¡¨æ€§çš„è®°å¿†è¿›è¡Œè¯¦ç»†åˆ†æ
    memory = memories[1]  # æƒ…æ„Ÿè®°å¿†
    context = contexts[0]  # æƒ…æ„Ÿå¯¹è¯åœºæ™¯
    
    print(f"ğŸ“ åˆ†æè®°å¿†: {memory.content}")
    print(f"ğŸ¯ åˆ†æåœºæ™¯: {context.get('scenario_type', 'default')}")
    print()
    
    # è®¡ç®—è¯¦ç»†å¾—åˆ†
    result = scorer.calculate_score(memory, context)
    
    print("ğŸ“Š å„ç»´åº¦å¾—åˆ†:")
    print(f"  æ—¶é—´ç»´åº¦ (Temporal):  {result.temporal_score:.3f}")
    print(f"  è¯­ä¹‰ç»´åº¦ (Semantic):  {result.semantic_score:.3f}")
    print(f"  ç¤¾äº¤ç»´åº¦ (Social):    {result.social_score:.3f}")
    print(f"  æƒ…æ„Ÿç»´åº¦ (Emotional): {result.emotional_score:.3f}")
    print(f"  è´¨é‡ç»´åº¦ (Quality):   {result.quality_score:.3f}")
    print()
    
    print("âš–ï¸ æƒé‡é…ç½®:")
    weights = result.weights_used
    print(f"  æ—¶é—´æƒé‡: {weights.temporal:.2f}")
    print(f"  è¯­ä¹‰æƒé‡: {weights.semantic:.2f}")
    print(f"  ç¤¾äº¤æƒé‡: {weights.social:.2f}")
    print(f"  æƒ…æ„Ÿæƒé‡: {weights.emotional:.2f}")
    print(f"  è´¨é‡æƒé‡: {weights.quality:.2f}")
    print()
    
    print("ğŸ¯ æœ€ç»ˆç»“æœ:")
    print(f"  åŠ æƒå¾—åˆ†: {result.weighted_score:.3f}")
    print(f"  æœ€ç»ˆå¾—åˆ†: {result.final_score:.3f}")
    print(f"  åœºæ™¯ç±»å‹: {result.scenario_type.value}")
    print()
    
    print("ğŸ”¬ è®¡ç®—å…ƒæ•°æ®:")
    metadata = result.calculation_metadata
    for key, value in metadata.items():
        print(f"  {key}: {value}")


def benchmark_performance():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\nâš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 60)
    
    import time
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    memories = create_test_memories() * 10  # 50æ¡è®°å¿†
    context = create_test_contexts()[0]
    
    # æµ‹è¯•ä¼ ç»ŸRIFè¯„åˆ†æ€§èƒ½
    traditional_scorer = RIFScorer(use_multidimensional=False)
    
    start_time = time.time()
    for memory in memories:
        traditional_scorer.calculate_rif(memory)
    traditional_time = time.time() - start_time
    
    # æµ‹è¯•å¤šç»´åº¦è¯„åˆ†æ€§èƒ½
    multidimensional_scorer = RIFScorer(use_multidimensional=True)
    
    start_time = time.time()
    for memory in memories:
        multidimensional_scorer.calculate_rif(memory, context)
    multidimensional_time = time.time() - start_time
    
    print(f"ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ ({len(memories)} æ¡è®°å¿†):")
    print(f"  ä¼ ç»ŸRIF:   {traditional_time:.3f}ç§’ ({traditional_time/len(memories)*1000:.2f}ms/æ¡)")
    print(f"  å¤šç»´åº¦:    {multidimensional_time:.3f}ç§’ ({multidimensional_time/len(memories)*1000:.2f}ms/æ¡)")
    print(f"  æ€§èƒ½æ¯”ä¾‹:  {multidimensional_time/traditional_time:.2f}x (å¤šç»´åº¦ç›¸å¯¹äºä¼ ç»Ÿ)")
    
    if multidimensional_time > traditional_time:
        print(f"  âš ï¸  å¤šç»´åº¦è¯„åˆ†è¾ƒæ…¢ {(multidimensional_time/traditional_time-1)*100:.1f}%")
    else:
        print(f"  âœ… å¤šç»´åº¦è¯„åˆ†æ›´å¿« {(1-multidimensional_time/traditional_time)*100:.1f}%")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        # è¿è¡Œå¯¹æ¯”æµ‹è¯•
        await run_comparison_test()
        
        # è¯¦ç»†åˆ†æ
        analyze_detailed_scores()
        
        # æ€§èƒ½æµ‹è¯•
        benchmark_performance()
        
        print("\nâœ… æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("1. åœ¨æƒ…æ„Ÿå¯¹è¯åœºæ™¯ä¸­ï¼Œå¤šç»´åº¦è¯„åˆ†æ›´å‡†ç¡®åœ°è¯†åˆ«æƒ…æ„Ÿè®°å¿†çš„é‡è¦æ€§")
        print("2. åœ¨äº‹å®æŸ¥è¯¢åœºæ™¯ä¸­ï¼Œè´¨é‡ç»´åº¦å’Œè¯­ä¹‰ç»´åº¦æƒé‡æ›´é«˜ï¼Œæå‡æŸ¥è¯¢å‡†ç¡®æ€§")  
        print("3. ç¤¾äº¤åœºæ™¯ä¸­ï¼Œå…³ç³»è®°å¿†å’Œç¾¤ä½“ç›¸å…³æ€§å¾—åˆ°æ›´å¥½çš„è¯„ä¼°")
        print("4. å¤šç»´åº¦è¯„åˆ†è™½ç„¶è®¡ç®—å¤æ‚ï¼Œä½†æä¾›äº†æ›´ç²¾ç»†çš„è®°å¿†ä»·å€¼è¯„ä¼°")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())